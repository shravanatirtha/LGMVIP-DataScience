<NeuralDesignerOutput>
 <Task Name="Calculate columns distribution" Title="Data distribution" Component="Data set" Id="Q7b22L">
  <Text Title="Task description" Id="maVE80">Histograms show how the data is distributed over its entire range.&#xd;
In classification problems, a uniform distribution for all the variables is, in general, desirable.&#xd;
If the data is very irregularly distributed, then the model will probably be of bad quality. </Text>
  <HistogramChart Title="sepal_length distribution" Id="3TIBuU">
   <Caption Id="xzNDkF">The following chart shows the histogram for the variable sepal_length.&#xd;
 The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies.&#xd;
The maximum frequency is 18%, which corresponds to the bin with center 5.56. &#xd;
The minimum frequency is 3.33333%, which corresponds to the bin with center 7.36. </Caption>
   <Name>sepal_length</Name>
   <NominalNames/>
   <Centers>4.48\4.84\5.2\5.56\5.92\6.28\6.64\7\7.36\7.72</Centers>
   <Frequencies>6\15.3\9.33\18\14.7\13.3\12\4\3.33\4</Frequencies>
   <Minimums>4.3\4.66\5.02\5.38\5.74\6.1\6.46\6.82\7.18\7.54</Minimums>
   <Maximums>4.66\5.02\5.38\5.74\6.1\6.46\6.82\7.18\7.54\7.9</Maximums>
   <Minimum>0</Minimum>
   <Maximum>110</Maximum>
  </HistogramChart>
  <HistogramChart Title="sepal_width distribution" Id="Pcrk1o">
   <Caption Id="ygj1ij">The following chart shows the histogram for the variable sepal_width.&#xd;
 The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies.&#xd;
The maximum frequency is 25.3333%, which corresponds to the bin with center 3.08. &#xd;
The minimum frequency is 1.33333%, which corresponds to the bins with centers 4.04, 4.28. </Caption>
   <Name>sepal_width</Name>
   <NominalNames/>
   <Centers>2.12\2.36\2.6\2.84\3.08\3.32\3.56\3.8\4.04\4.28</Centers>
   <Frequencies>2.67\4.67\14.7\16\25.3\20.7\6\7.33\1.33\1.33</Frequencies>
   <Minimums>2\2.24\2.48\2.72\2.96\3.2\3.44\3.68\3.92\4.16</Minimums>
   <Maximums>2.24\2.48\2.72\2.96\3.2\3.44\3.68\3.92\4.16\4.4</Maximums>
   <Minimum>0</Minimum>
   <Maximum>110</Maximum>
  </HistogramChart>
  <HistogramChart Title="petal_length distribution" Id="nWmYEF">
   <Caption Id="coytl9">The following chart shows the histogram for the variable petal_length.&#xd;
 The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies.&#xd;
The maximum frequency is 24.6667%, which corresponds to the bin with center 1.3. &#xd;
The minimum frequency is 0%, which corresponds to the bin with center 2.47. </Caption>
   <Name>petal_length</Name>
   <NominalNames/>
   <Centers>1.3\1.88\2.47\3.07\3.66\4.25\4.84\5.43\6.02\6.61</Centers>
   <Frequencies>24.7\8.67\0\2\5.33\17.3\19.3\12\7.33\3.33</Frequencies>
   <Minimums>1\1.59\2.18\2.77\3.36\3.95\4.54\5.13\5.72\6.31</Minimums>
   <Maximums>1.59\2.18\2.77\3.36\3.95\4.54\5.13\5.72\6.31\6.9</Maximums>
   <Minimum>0</Minimum>
   <Maximum>110</Maximum>
  </HistogramChart>
  <HistogramChart Title=" petal_width distribution" Id="k0XrQ5">
   <Caption Id="aAtOXv">The following chart shows the histogram for the variable  petal_width.&#xd;
 The abscissa represents the centers of the containers, and the ordinate their corresponding frequencies.&#xd;
The maximum frequency is 27.3333%, which corresponds to the bin with center 0.22. &#xd;
The minimum frequency is 0.666667%, which corresponds to the bin with center 0.7. </Caption>
   <Name> petal_width</Name>
   <NominalNames/>
   <Centers>0.22\0.46\0.7\0.94\1.18\1.42\1.66\1.9\2.14\2.38</Centers>
   <Frequencies>27.3\5.33\0.667\4.67\14\13.3\4\15.3\6\9.33</Frequencies>
   <Minimums>0.1\0.34\0.58\0.82\1.06\1.3\1.54\1.78\2.02\2.26</Minimums>
   <Maximums>0.34\0.58\0.82\1.06\1.3\1.54\1.78\2.02\2.26\2.5</Maximums>
   <Minimum>0</Minimum>
   <Maximum>110</Maximum>
  </HistogramChart>
  <PieChart Title="class distribution pie chart" Id="vMLSK2">
   <Caption Id="55p0Yq">The following pie chart shows the distribution for the categorical variable class, which contains 3 variables: iris_setosa, iris_versicolor and iris_virginica.&#xd;
 The minimum frequency is 33.3333%, which corresponds to the categories iris_setosa, iris_setosa and iris_versicolor.&#xd;
The maximum frequency is 33.3333%, which corresponds to the categories iris_setosa, iris_setosa and iris_versicolor.</Caption>
   <Data>33.3333\33.3333\33.3333</Data>
   <Names Id="wpJBbq">iris_setosa\iris_versicolor\iris_virginica</Names>
  </PieChart>
 </Task>
 <Task Name="Report neural network" Title="Neural network" Component="Neural network" Id="y5Riqn">
  <Text Title="Task description" Id="OE9UTc">The neural network represents the predictive model. In Neural Designer neural networks allow deep architectures, which are a class of universal approximator. </Text>
  <Table Title="Inputs" Id="7JKSMw">
   <Caption Id="BoBsqR">The number of inputs is 4.&#xd;
The next table depicts the names of the inputs to the neural network.&#xd;
</Caption>
   <Data>sepal_length&#xd;
sepal_width&#xd;
petal_length&#xd;
 petal_width</Data>
   <RowsName>1\2\3\4</RowsName>
   <ColumnsName>  Name   </ColumnsName>
   <RowHeadingsWidth>3</RowHeadingsWidth>
   <ColumnHeadingsWidth>12</ColumnHeadingsWidth>
   <Alignment>left</Alignment>
  </Table>
  <Table Title="Scaling layer" Id="VFzssc">
   <Caption Id="rQ9MSK">The size of the scaling layer is 4, the number of inputs. The following table shows the values which are used for scaling the inputs, which include the minimum, maximum, mean and standard deviation. </Caption>
   <Data>4.3\7.9\5.84333\0.828066\MeanStandardDeviation&#xd;
2\4.4\3.054\0.433594\MeanStandardDeviation&#xd;
1\6.9\3.75867\1.76442\MeanStandardDeviation&#xd;
0.1\2.5\1.19867\0.763161\MeanStandardDeviation</Data>
   <RowsName>sepal_length\sepal_width\petal_length\ petal_width</RowsName>
   <ColumnsName>Minimum\Maximum\Mean\Deviation\Scaler</ColumnsName>
   <RowHeadingsWidth>9</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Perceptron layers" Id="6XACYj">
   <Caption Id="5BYd51">The number of perceptron layers in the neural network is 1. The following table depicts the size of each layer and its corresponding activation function. </Caption>
   <Data>4\3\HyperbolicTangent</Data>
   <RowsName>1</RowsName>
   <ColumnsName>Inputs number\Neurons number\Activation function</ColumnsName>
   <RowHeadingsWidth>5</RowHeadingsWidth>
   <ColumnHeadingsWidth>14</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Probabilistic layer" Id="HvwHpb">
   <Caption Id="ewRSsw">The following table depicts the size of the probabilistic layer the corresponding activation function. </Caption>
   <Data>3\3\Softmax</Data>
   <RowsName>1</RowsName>
   <ColumnsName>Inputs number\Neurons number\Activation function</ColumnsName>
   <RowHeadingsWidth>5</RowHeadingsWidth>
   <ColumnHeadingsWidth>14</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Outputs table" Id="Ep3LPa">
   <Caption Id="0YOrMq">The number of outputs is 3. The next table depicts the name of the outputs from the neural network.&#xd;
</Caption>
   <Data>iris_setosa&#xd;
iris_versicolor&#xd;
iris_virginica</Data>
   <RowsName>1\2\3</RowsName>
   <ColumnsName>  Name   </ColumnsName>
   <RowHeadingsWidth>3</RowHeadingsWidth>
   <ColumnHeadingsWidth>12</ColumnHeadingsWidth>
   <Alignment>left</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Network architecture" Id="CmUGrZ">
   <Caption Id="2VmaYc">A graphical representation of the resulted deep architecture is depicted next.&#xd;
It contains the following layers:&#xd;
-Scaling layer with 4 neurons (yellow).&#xd;
-Perceptron layer with 3 neurons (blue).&#xd;
-Probabilistic layer with 3 neurons (red).&#xd;
</Caption>
   <ProjectType>classification</ProjectType>
   <InputsName>sepal_length\sepal_width\petal_length\ petal_width</InputsName>
   <OutputsName>iris_setosa\iris_versicolor\iris_virginica</OutputsName>
   <LayersName>scaling_layer\perceptron_layer_1\probabilistic_layer</LayersName>
   <Architecture>4\3\3</Architecture>
  </NeuralNetworkGraph>
 </Task>
 <Task Name="Report training strategy" Title="Training strategy" Component="Training strategy" Id="wHEINN">
  <Text Title="Training strategy" Id="4dk7p4">The procedure used to carry out the learning process is called training (or learning) strategy.&#xd;
The training strategy is applied to the neural network in order to obtain the best possible loss.&#xd;
</Text>
  <Text Title="Loss index" Id="ij4WQp">The loss index defines the task the neural network is requiered to do and provides a measure of the quality of the representation requiered to learn.&#xd;
When setting a loss index, two different terms must be chosen: an error term and a regularization term. &#xd;
&#xd;
The error term evaluates quantitatively how the neural network fits the data set. There are several error methods, and the choice of an appropriate one depends on the particular application. In this case, the Normalized Squared Error (MSE) is selected. The normalized squared error has a value of one when the outputs from the neural network are equal to the mean values of the target variables, while a value of zero means perfect prediction of the data. &#xd;
&#xd;
 The regularization term measures the values of the parameters in the neural network. Adding it to the error will cause the neural network to have smaller weights and biases, which will force its response to be smoother, i.e., to avoid overfitting. In this case, L2 regularization method is applied. It consists of the squared sum of all the parameters in the neural network. </Text>
  <Table Title="Optimization algorithm" Id="p7Qb63">
   <Caption Id="shVxqU">The quasi-Newton method is used here as optimization algorithm.&#xd;
It is based on Newton's method, but does not require calculation of second derivatives.&#xd;
Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Caption>
   <Data>Method used to obtain a suitable training rate.\BFGS&#xd;
Method used to calculate the step for the quasi-Newton training direction.\BrentMethod&#xd;
Maximum interval length for the learning rate.\0.001000&#xd;
Minimum loss improvement between two successive epochs.\0.000000&#xd;
Goal value for the loss.\0.001000&#xd;
Goal value for the norm of the objective function gradient.\100&#xd;
Maximum number of epochs at which the selection error increases.\1000&#xd;
Maximum number of epochs to perform the training.\01:00:00</Data>
   <RowsName>Inverse hessian approximation method\Learning rate method\Learning rate tolerance\Minimum loss decrease\Loss goal\Maximum selection error increases\Maximum epochs number\Maximum time</RowsName>
   <ColumnsName>Description\Value</ColumnsName>
   <RowHeadingsWidth>27</RowHeadingsWidth>
   <ColumnHeadingsWidth>25</ColumnHeadingsWidth>
   <Alignment>center</Alignment>
  </Table>
 </Task>
 <Task Name="Perform training" Title="Training" Component="Training strategy" Id="QrDldZ">
  <Text Title="Task description" Id="l42QVW">The procedure used to carry out the learning process is called training (or learning) strategy.&#xd;
The training strategy is applied to the neural network in order to obtain the best possible loss.&#xd;
The type of training is determined by the way in which the adjustment of the parameters in the neural network takes place.&#xd;
</Text>
  <Text Title="Optimization algorithm" Id="NlIc7J">The quasi-Newton method is used here for training.&#xd;
It is based on Newton's method, but does not require calculation of second derivatives.&#xd;
Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Text>
  <DoubleLineChart Title="Quasi-Newton method errors history" Id="7SkHo2">
   <Caption Id="zny6DB">The following plot shows the training and selection errors in each iteration.&#xd;
The blue line represents the training error and the orange line represents the selection error.&#xd;
The initial value of the training error is 1.04195, and the final value after 91 epochs is 0.0547881.&#xd;
The initial value of the selection error is 1.03602, and the final value after 91 epochs is 0.00435.&#xd;
</Caption>
   <X1Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81\82\83\84\85\86\87\88\89\90\91</X1Data>
   <X2Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81\82\83\84\85\86\87\88\89\90\91</X2Data>
   <Y1Data>1.04\0.953\0.511\0.475\0.356\0.286\0.256\0.184\0.125\0.08\0.076\0.074\0.0755\0.0709\0.0656\0.0606\0.0603\0.0575\0.0577\0.0564\0.0565\0.0549\0.0566\0.0572\0.0568\0.0568\0.0573\0.0537\0.0552\0.0555\0.0555\0.0554\0.0549\0.0555\0.0552\0.0551\0.0548\0.0555\0.0551\0.0551\0.0552\0.055\0.0551\0.0551\0.055\0.0547\0.0548\0.055\0.0552\0.055\0.0547\0.0548\0.0549\0.055\0.0548\0.0549\0.0547\0.0549\0.0552\0.0549\0.0548\0.0549\0.0548\0.0547\0.0546\0.055\0.0549\0.0548\0.0548\0.0549\0.055\0.0546\0.0547\0.0547\0.0547\0.0547\0.0548\0.0548\0.0547\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548\0.0548</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>1.04\0.958\0.485\0.46\0.303\0.313\0.295\0.187\0.12\0.0205\0.0194\0.0196\0.0232\0.0168\0.0149\0.01\0.0105\0.00911\0.00812\0.00758\0.00537\0.00483\0.00612\0.00717\0.00678\0.00596\0.00664\0.00516\0.00763\0.00818\0.00783\0.0076\0.00541\0.00489\0.00469\0.0045\0.00409\0.00445\0.00501\0.00512\0.00554\0.0043\0.00436\0.00441\0.00437\0.00417\0.00433\0.00434\0.00445\0.00439\0.00402\0.00412\0.00421\0.00429\0.00416\0.00427\0.0047\0.00526\0.00555\0.00499\0.00521\0.00534\0.00533\0.00557\0.00563\0.00502\0.00474\0.00476\0.00476\0.00461\0.00474\0.00427\0.00437\0.00437\0.00433\0.00433\0.00439\0.00441\0.00437\0.0044\0.00442\0.00443\0.00438\0.00436\0.00435\0.00435\0.00435\0.00436\0.00435\0.00435\0.00435\0.00435</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Epoch</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>0</XMinimum>
   <XMaximum>92</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>2</YMaximum>
   <Dates>false</Dates>
  </DoubleLineChart>
  <Table Title="Quasi-Newton method results" Id="8BB9A0">
   <Caption Id="Pev3xB">The next table shows the training results by the quasi-Newton method.&#xd;
They include some final states from the neural network, the loss index and the optimization algorithm.&#xd;
</Caption>
   <Data>0.0548&#xd;
0.00435&#xd;
91&#xd;
00:00:00&#xd;
Minimum loss decrease&#xd;
</Data>
   <RowsName>Training error\Selection error\Epochs number\Elapsed time\Stopping criterion\</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>13</RowHeadingsWidth>
   <ColumnHeadingsWidth>20</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Name="Perform neurons selection" Title="Order selection" Component="Model selection" Id="8Tukl9">
  <Text Title="Task description" Id="k67lWx">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data.&#xd;
The neurons selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Neurons selection algorithm" Id="CowGZ2">The growing neurons algorithm is used here to select the optimal order in the neural network. </Text>
  <DoubleLineChart Title="Growing neurons training/selection errors plot" Id="dUGND3">
   <Caption Id="7YyoW9">The next chart shows the error history for the different subsets during the growing neurons selection process.&#xd;
The blue line represents the training error and the yellow line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.0838295\0.0552651\0.0547859\0.0545895\0.0543971\0.0542795\0.054189\0.0533302\0.0527869\0.0530902</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.0341787\0.00466337\0.00434984\0.00375036\0.0036991\0.00372926\0.00378988\0.00374064\0.00366208\0.00375003</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Neurons number</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
   <Dates>false</Dates>
  </DoubleLineChart>
  <Table Title="Growing neurons results" Id="fO1y2H">
   <Caption Id="TJOUhW">The next table shows the neurons selection results by the growing neurons algorithm.&#xd;
They include some final states from the neural network, the error functional and the neurons selection algorithm. </Caption>
   <Data>9&#xd;
0.0527869&#xd;
0.00366208&#xd;
10&#xd;
00:00:02&#xd;
</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Epochs number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Network architecture" Id="TfRqJR">
   <Caption Id="Pq1Ejv">A graphical representation of the resulted deep architecture is depicted next.&#xd;
It contains the following layers:&#xd;
-Scaling layer with 4 neurons (yellow).&#xd;
-Perceptron layer with 9 neurons (blue).&#xd;
-Probabilistic layer with 3 neurons (red).&#xd;
</Caption>
   <ProjectType>classification</ProjectType>
   <InputsName>sepal_length\sepal_width\petal_length\ petal_width</InputsName>
   <OutputsName>iris_setosa\iris_versicolor\iris_virginica</OutputsName>
   <LayersName>scaling_layer\perceptron_layer_1\probabilistic_layer</LayersName>
   <Architecture>4\9\3</Architecture>
  </NeuralNetworkGraph>
 </Task>
 <Task Name="Calculate confusion" Title="Confusion" Component="Testing analysis" Id="llTz4e">
  <Text Title="Task description" Id="LkzCA4">In the confusion matrix the rows represent the target classes and the columns the output classes for the testing target data set. The diagonal cells in each table show the number of cases that were correctly classified, and the off-diagonal cells show the misclassified cases. </Text>
  <Table Title="Confusion table" Id="wghL8W">
   <Caption Id="cci7a9">The following table contains the elements of the confusion matrix.&#xd;
The total number of testing samples is 30.&#xd;
The number of correctly classified samples is 28 (93.3%), and the number of misclassified samples is 2 (6.7%).&#xd;
</Caption>
   <Data>11 (36.7%)\0\0&#xd;
0\8 (26.7%)\1 (3.3%)&#xd;
0\1 (3.3%)\9 (30.0%)</Data>
   <RowsName>Real iris_setosa\Real iris_versicolor\Real iris_virginica</RowsName>
   <ColumnsName>Predicted iris_setosa\Predicted iris_versicolor\Predicted iris_virginica</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>18</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Name="Perform training" Title="Training" Component="Training strategy" Id="fDWPdC">
  <Text Title="Task description" Id="ZTsDYf">The procedure used to carry out the learning process is called training (or learning) strategy.&#xd;
The training strategy is applied to the neural network in order to obtain the best possible loss.&#xd;
The type of training is determined by the way in which the adjustment of the parameters in the neural network takes place.&#xd;
</Text>
  <Text Title="Optimization algorithm" Id="OwRON1">The quasi-Newton method is used here for training.&#xd;
It is based on Newton's method, but does not require calculation of second derivatives.&#xd;
Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Text>
  <DoubleLineChart Title="Quasi-Newton method errors history" Id="2qfNMe">
   <Caption Id="Xsoy1m">The following plot shows the training and selection errors in each iteration.&#xd;
The blue line represents the training error and the orange line represents the selection error.&#xd;
The initial value of the training error is 0.0527869, and the final value after 16 epochs is 0.0528395.&#xd;
The initial value of the selection error is 0.00366207, and the final value after 16 epochs is 0.00367739.&#xd;
</Caption>
   <X1Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16</X1Data>
   <X2Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16</X2Data>
   <Y1Data>0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528\0.0528</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.00366\0.00366\0.00366\0.00365\0.00365\0.00366\0.00366\0.00367\0.00367\0.00368\0.00368\0.00366\0.00366\0.00366\0.00367\0.00368\0.00368</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Epoch</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>0</XMinimum>
   <XMaximum>17</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
   <Dates>false</Dates>
  </DoubleLineChart>
  <Table Title="Quasi-Newton method results" Id="nv8RUy">
   <Caption Id="vnTcsa">The next table shows the training results by the quasi-Newton method.&#xd;
They include some final states from the neural network, the loss index and the optimization algorithm.&#xd;
</Caption>
   <Data>0.0528&#xd;
0.00368&#xd;
16&#xd;
00:00:00&#xd;
Minimum loss decrease&#xd;
</Data>
   <RowsName>Training error\Selection error\Epochs number\Elapsed time\Stopping criterion\</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>13</RowHeadingsWidth>
   <ColumnHeadingsWidth>20</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Name="Perform neurons selection" Title="Order selection" Component="Model selection" Id="BHPWja">
  <Text Title="Task description" Id="c4OdmA">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data.&#xd;
The neurons selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Neurons selection algorithm" Id="MbvGa0">The growing neurons algorithm is used here to select the optimal order in the neural network. </Text>
  <DoubleLineChart Title="Growing neurons training/selection errors plot" Id="cxkB0j">
   <Caption Id="luRbAb">The next chart shows the error history for the different subsets during the growing neurons selection process.&#xd;
The blue line represents the training error and the yellow line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.0838184\0.0552628\0.0547911\0.0546085\0.054394\0.0542785\0.0534813\0.0532926\0.0524035\0.0531963</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.034188\0.00465797\0.00434982\0.0043696\0.00369717\0.00372491\0.00374244\0.003722\0.00352931\0.00377504</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Neurons number</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
   <Dates>false</Dates>
  </DoubleLineChart>
  <Table Title="Growing neurons results" Id="x4m29Q">
   <Caption Id="Lt1QVy">The next table shows the neurons selection results by the growing neurons algorithm.&#xd;
They include some final states from the neural network, the error functional and the neurons selection algorithm. </Caption>
   <Data>9&#xd;
0.0524035&#xd;
0.00352931&#xd;
10&#xd;
00:00:01&#xd;
</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Epochs number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Network architecture" Id="aGgXGm">
   <Caption Id="G48ZM3">A graphical representation of the resulted deep architecture is depicted next.&#xd;
It contains the following layers:&#xd;
-Scaling layer with 4 neurons (yellow).&#xd;
-Perceptron layer with 9 neurons (blue).&#xd;
-Probabilistic layer with 3 neurons (red).&#xd;
</Caption>
   <ProjectType>classification</ProjectType>
   <InputsName>sepal_length\sepal_width\petal_length\ petal_width</InputsName>
   <OutputsName>iris_setosa\iris_versicolor\iris_virginica</OutputsName>
   <LayersName>scaling_layer\perceptron_layer_1\probabilistic_layer</LayersName>
   <Architecture>4\9\3</Architecture>
  </NeuralNetworkGraph>
 </Task>
 <Task Name="Calculate confusion" Title="Confusion" Component="Testing analysis" Id="U89mGl">
  <Text Title="Task description" Id="VS9GGr">In the confusion matrix the rows represent the target classes and the columns the output classes for the testing target data set. The diagonal cells in each table show the number of cases that were correctly classified, and the off-diagonal cells show the misclassified cases. </Text>
  <Table Title="Confusion table" Id="IRxzr2">
   <Caption Id="tpYPv8">The following table contains the elements of the confusion matrix.&#xd;
The total number of testing samples is 30.&#xd;
The number of correctly classified samples is 28 (93.3%), and the number of misclassified samples is 2 (6.7%).&#xd;
</Caption>
   <Data>11 (36.7%)\0\0&#xd;
0\8 (26.7%)\1 (3.3%)&#xd;
0\1 (3.3%)\9 (30.0%)</Data>
   <RowsName>Real iris_setosa\Real iris_versicolor\Real iris_virginica</RowsName>
   <ColumnsName>Predicted iris_setosa\Predicted iris_versicolor\Predicted iris_virginica</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>18</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
</NeuralDesignerOutput>
